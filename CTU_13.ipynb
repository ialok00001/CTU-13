{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# To ignore all warnings (not recommended in most cases)\n",
    "warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing one of the 13 datasets\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Hp\\\\Downloads\\\\CTU-13\\\\1-Neris-20110810.binetflow.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartTime</th>\n",
       "      <th>Dur</th>\n",
       "      <th>Proto</th>\n",
       "      <th>SrcAddr</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Dir</th>\n",
       "      <th>DstAddr</th>\n",
       "      <th>Dport</th>\n",
       "      <th>State</th>\n",
       "      <th>sTos</th>\n",
       "      <th>dTos</th>\n",
       "      <th>TotPkts</th>\n",
       "      <th>TotBytes</th>\n",
       "      <th>SrcBytes</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011/08/10 09:46:59.607825</td>\n",
       "      <td>1.026539</td>\n",
       "      <td>tcp</td>\n",
       "      <td>94.44.127.113</td>\n",
       "      <td>1577</td>\n",
       "      <td>-&gt;</td>\n",
       "      <td>147.32.84.59</td>\n",
       "      <td>6881</td>\n",
       "      <td>S_RA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>276</td>\n",
       "      <td>156</td>\n",
       "      <td>flow=Background-Established-cmpgw-CVUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011/08/10 09:47:00.634364</td>\n",
       "      <td>1.009595</td>\n",
       "      <td>tcp</td>\n",
       "      <td>94.44.127.113</td>\n",
       "      <td>1577</td>\n",
       "      <td>-&gt;</td>\n",
       "      <td>147.32.84.59</td>\n",
       "      <td>6881</td>\n",
       "      <td>S_RA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>276</td>\n",
       "      <td>156</td>\n",
       "      <td>flow=Background-Established-cmpgw-CVUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011/08/10 09:47:48.185538</td>\n",
       "      <td>3.056586</td>\n",
       "      <td>tcp</td>\n",
       "      <td>147.32.86.89</td>\n",
       "      <td>4768</td>\n",
       "      <td>-&gt;</td>\n",
       "      <td>77.75.73.33</td>\n",
       "      <td>80</td>\n",
       "      <td>SR_A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>182</td>\n",
       "      <td>122</td>\n",
       "      <td>flow=Background-TCP-Attempt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011/08/10 09:47:48.230897</td>\n",
       "      <td>3.111769</td>\n",
       "      <td>tcp</td>\n",
       "      <td>147.32.86.89</td>\n",
       "      <td>4788</td>\n",
       "      <td>-&gt;</td>\n",
       "      <td>77.75.73.33</td>\n",
       "      <td>80</td>\n",
       "      <td>SR_A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>182</td>\n",
       "      <td>122</td>\n",
       "      <td>flow=Background-TCP-Attempt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011/08/10 09:47:48.963351</td>\n",
       "      <td>3.083411</td>\n",
       "      <td>tcp</td>\n",
       "      <td>147.32.86.89</td>\n",
       "      <td>4850</td>\n",
       "      <td>-&gt;</td>\n",
       "      <td>77.75.73.33</td>\n",
       "      <td>80</td>\n",
       "      <td>SR_A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>182</td>\n",
       "      <td>122</td>\n",
       "      <td>flow=Background-TCP-Attempt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    StartTime       Dur Proto        SrcAddr Sport    Dir  \\\n",
       "0  2011/08/10 09:46:59.607825  1.026539   tcp  94.44.127.113  1577     ->   \n",
       "1  2011/08/10 09:47:00.634364  1.009595   tcp  94.44.127.113  1577     ->   \n",
       "2  2011/08/10 09:47:48.185538  3.056586   tcp   147.32.86.89  4768     ->   \n",
       "3  2011/08/10 09:47:48.230897  3.111769   tcp   147.32.86.89  4788     ->   \n",
       "4  2011/08/10 09:47:48.963351  3.083411   tcp   147.32.86.89  4850     ->   \n",
       "\n",
       "        DstAddr Dport State  sTos  dTos  TotPkts  TotBytes  SrcBytes  \\\n",
       "0  147.32.84.59  6881  S_RA   0.0   0.0        4       276       156   \n",
       "1  147.32.84.59  6881  S_RA   0.0   0.0        4       276       156   \n",
       "2   77.75.73.33    80  SR_A   0.0   0.0        3       182       122   \n",
       "3   77.75.73.33    80  SR_A   0.0   0.0        3       182       122   \n",
       "4   77.75.73.33    80  SR_A   0.0   0.0        3       182       122   \n",
       "\n",
       "                                    Label  \n",
       "0  flow=Background-Established-cmpgw-CVUT  \n",
       "1  flow=Background-Established-cmpgw-CVUT  \n",
       "2             flow=Background-TCP-Attempt  \n",
       "3             flow=Background-TCP-Attempt  \n",
       "4             flow=Background-TCP-Attempt  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2824636, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to date-time\n",
    "df[\"StartTime\"] = pd.to_datetime(df[\"StartTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StartTime -> datetime64[ns]\n",
      "Dur -> float64\n",
      "Proto -> object\n",
      "SrcAddr -> object\n",
      "Sport -> object\n",
      "Dir -> object\n",
      "DstAddr -> object\n",
      "Dport -> object\n",
      "State -> object\n",
      "sTos -> float64\n",
      "dTos -> float64\n",
      "TotPkts -> int64\n",
      "TotBytes -> int64\n",
      "SrcBytes -> int64\n",
      "Label -> object\n"
     ]
    }
   ],
   "source": [
    "for x in df:\n",
    "    print(f\"{x} -> {df[x].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An exploration on variables\n",
    "\n",
    "* Categorical Columns -> Proto (15), Dir (7), State (230) (nan=1), Sport (nan=9379),  Dport (nan = 4390)\n",
    "* Numerical columns -> Dur, sTos (nan = 10590), dTos (nan = 195190), TotPkts, TotBytes, SrcBytes\n",
    "* Something (close to numerical but expressed in string) -> SrcAddr,  DstAddr\n",
    "* Time Series -> StartTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StartTime -> 0\n",
      "Dur -> 0\n",
      "Proto -> 0\n",
      "SrcAddr -> 0\n",
      "Sport -> 0\n",
      "Dir -> 0\n",
      "DstAddr -> 0\n",
      "Dport -> 0\n",
      "State -> 0\n",
      "sTos -> 0\n",
      "dTos -> 0\n",
      "TotPkts -> 0\n",
      "TotBytes -> 0\n",
      "SrcBytes -> 0\n",
      "Label -> 0\n"
     ]
    }
   ],
   "source": [
    "# Dropping the only row with a nan State value\n",
    "df = df.dropna(subset=[\"State\"])\n",
    "\n",
    "# Filling \"Unknown\" in place of nan values in Sport and Dport\n",
    "df['Sport'].fillna('unknown', inplace=True)\n",
    "df['Dport'].fillna('unknown', inplace=True)\n",
    "\n",
    "# Replacing the nan values in sTos and dTos with the median of respective columns\n",
    "df['sTos'].fillna(df[\"sTos\"].median(), inplace=True)\n",
    "df['dTos'].fillna(df[\"dTos\"].median(), inplace=True)\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Checking for any leftover nan values in each columns\n",
    "for column in df:\n",
    "    print(f\"{column} -> {df[column].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we have dealt with all the NaN values in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartTime</th>\n",
       "      <th>Dur</th>\n",
       "      <th>Proto</th>\n",
       "      <th>SrcAddr</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Dir</th>\n",
       "      <th>DstAddr</th>\n",
       "      <th>Dport</th>\n",
       "      <th>State</th>\n",
       "      <th>sTos</th>\n",
       "      <th>dTos</th>\n",
       "      <th>TotPkts</th>\n",
       "      <th>TotBytes</th>\n",
       "      <th>SrcBytes</th>\n",
       "      <th>Label</th>\n",
       "      <th>PacketsPerSec</th>\n",
       "      <th>BytesPerSec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-08-10 09:46:59.607825</td>\n",
       "      <td>1.026539</td>\n",
       "      <td>11</td>\n",
       "      <td>94.44.127.113</td>\n",
       "      <td>6373</td>\n",
       "      <td>0</td>\n",
       "      <td>147.32.84.59</td>\n",
       "      <td>70633</td>\n",
       "      <td>203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>276</td>\n",
       "      <td>156</td>\n",
       "      <td>3</td>\n",
       "      <td>3.896588</td>\n",
       "      <td>268.864602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-08-10 09:47:00.634364</td>\n",
       "      <td>1.009595</td>\n",
       "      <td>11</td>\n",
       "      <td>94.44.127.113</td>\n",
       "      <td>6373</td>\n",
       "      <td>0</td>\n",
       "      <td>147.32.84.59</td>\n",
       "      <td>70633</td>\n",
       "      <td>203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>276</td>\n",
       "      <td>156</td>\n",
       "      <td>3</td>\n",
       "      <td>3.961985</td>\n",
       "      <td>273.376948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-08-10 09:47:48.185538</td>\n",
       "      <td>3.056586</td>\n",
       "      <td>11</td>\n",
       "      <td>147.32.86.89</td>\n",
       "      <td>41591</td>\n",
       "      <td>0</td>\n",
       "      <td>77.75.73.33</td>\n",
       "      <td>71762</td>\n",
       "      <td>193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>182</td>\n",
       "      <td>122</td>\n",
       "      <td>4</td>\n",
       "      <td>0.981487</td>\n",
       "      <td>59.543556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-08-10 09:47:48.230897</td>\n",
       "      <td>3.111769</td>\n",
       "      <td>11</td>\n",
       "      <td>147.32.86.89</td>\n",
       "      <td>41812</td>\n",
       "      <td>0</td>\n",
       "      <td>77.75.73.33</td>\n",
       "      <td>71762</td>\n",
       "      <td>193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>182</td>\n",
       "      <td>122</td>\n",
       "      <td>4</td>\n",
       "      <td>0.964082</td>\n",
       "      <td>58.487632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-08-10 09:47:48.963351</td>\n",
       "      <td>3.083411</td>\n",
       "      <td>11</td>\n",
       "      <td>147.32.86.89</td>\n",
       "      <td>42496</td>\n",
       "      <td>0</td>\n",
       "      <td>77.75.73.33</td>\n",
       "      <td>71762</td>\n",
       "      <td>193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>182</td>\n",
       "      <td>122</td>\n",
       "      <td>4</td>\n",
       "      <td>0.972948</td>\n",
       "      <td>59.025540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   StartTime       Dur  Proto        SrcAddr  Sport  Dir  \\\n",
       "0 2011-08-10 09:46:59.607825  1.026539     11  94.44.127.113   6373    0   \n",
       "1 2011-08-10 09:47:00.634364  1.009595     11  94.44.127.113   6373    0   \n",
       "2 2011-08-10 09:47:48.185538  3.056586     11   147.32.86.89  41591    0   \n",
       "3 2011-08-10 09:47:48.230897  3.111769     11   147.32.86.89  41812    0   \n",
       "4 2011-08-10 09:47:48.963351  3.083411     11   147.32.86.89  42496    0   \n",
       "\n",
       "        DstAddr  Dport  State  sTos  dTos  TotPkts  TotBytes  SrcBytes  Label  \\\n",
       "0  147.32.84.59  70633    203   0.0   0.0        4       276       156      3   \n",
       "1  147.32.84.59  70633    203   0.0   0.0        4       276       156      3   \n",
       "2   77.75.73.33  71762    193   0.0   0.0        3       182       122      4   \n",
       "3   77.75.73.33  71762    193   0.0   0.0        3       182       122      4   \n",
       "4   77.75.73.33  71762    193   0.0   0.0        3       182       122      4   \n",
       "\n",
       "   PacketsPerSec  BytesPerSec  \n",
       "0       3.896588   268.864602  \n",
       "1       3.961985   273.376948  \n",
       "2       0.981487    59.543556  \n",
       "3       0.964082    58.487632  \n",
       "4       0.972948    59.025540  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding Categorical Features using Label Encoding from scikit-learn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# The Categorical variables we have to encode\n",
    "categorical_cols = [\"Proto\", \"Dir\", \"State\", \"Sport\", \"Dport\"]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# Encoding the Labels to integers\n",
    "df[\"Label\"] = label_encoder.fit_transform(df[\"Label\"])\n",
    "\n",
    "# Creating New Features\n",
    "# Rate of packets per second\n",
    "df['PacketsPerSec'] = df['TotPkts'] / df['Dur']\n",
    "# Bytes per second\n",
    "df['BytesPerSec'] = df['TotBytes'] / df['Dur']\n",
    "\n",
    "# Replace any NaN or infinite values (with zero) generated during the feature engineering\n",
    "df.replace([float('inf'), -float('inf')], float('nan'), inplace=True)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-numeric columns and separate features (X) and target (y) variables\n",
    "X = df.select_dtypes(include=['number']).drop(['Label'], axis=1, errors='ignore')\n",
    "y = df['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary ML packages from scikit-learn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "\n",
    "# Import other necessary packages from scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "# Splitting the data into training and testing sets (70% training and 30% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying different models and checking their accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decision stump (decision tree with depth 1) is a good way to start making a decision tree model, since it gives us a base to compare our main model from a basic one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Decision Stump -> 0.7344354613159687\n",
      "Accuracy on full Decision Tree -> 0.9629993710105489\n"
     ]
    }
   ],
   "source": [
    "# First creating a decision stump for the start\n",
    "clf = DecisionTreeClassifier(max_depth = 1, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "print(f\"Accuracy on Decision Stump -> {clf.score(X_test, y_test)}\")\n",
    "\n",
    "# Now the full decision tree\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "print(f\"Accuracy on full Decision Tree -> {clf.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full decision tree has a depth of 54.\n",
    "\n",
    "Let's see for the accuracies for decision trees of different depths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Decision Tree with depth 5-> 0.9117278800459292\n",
      "Accuracy on Decision Tree with depth 10-> 0.9400383058116029\n",
      "Accuracy on Decision Tree with depth 15-> 0.9545534469920025\n",
      "Accuracy on Decision Tree with depth 20-> 0.9603665840208357\n",
      "Accuracy on Decision Tree with depth 25-> 0.9629344659077097\n",
      "Accuracy on Decision Tree with depth 30-> 0.9633947020914785\n",
      "Accuracy on Decision Tree with depth 35-> 0.9632755127208101\n",
      "Accuracy on Decision Tree with depth 40-> 0.9630878779689659\n",
      "Accuracy on Decision Tree with depth 45-> 0.9631693043707096\n",
      "Accuracy on Decision Tree with depth 50-> 0.9630725367628403\n",
      "Accuracy on Decision Tree with depth 54-> 0.9629993710105489\n"
     ]
    }
   ],
   "source": [
    "for i in [5,10, 15, 20, 25, 30, 35, 40, 45, 50, 54]:\n",
    "    clf = DecisionTreeClassifier(random_state=42, max_depth = i)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f\"Accuracy on Decision Tree with depth {i}-> {clf.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracies does not seem to deviate much from that of the full decision tree. We will choose a depth small enough to reduce computation and big enough to keep the accuracy high. The depth between 15 and 20 seems to match the description. Let's go with 17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on full Decision Tree -> 0.9574151719808212\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=42, max_depth = 17)\n",
    "clf.fit(X_train, y_train)\n",
    "print(f\"Accuracy on full Decision Tree -> {clf.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how Random Forest performs on the dataset instead of the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Random Forest Classifier -> 0.9574092715169267\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state = 42, max_depth = 17, n_estimators=10, max_features=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(f\"Accuracy on Random Forest Classifier -> {clf.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of Random Forest is very similar to that of Decision Tree. Also, the Random Forest took more time due to smaller features each time. Hence we can say that the overall performance of Decision Tree seems to be better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** - We will not be using any boosting algorithm such as AdaBoost, because of many reasons:\n",
    "1) The dataset is itself very large. So it will take a large amount of time to fit subsequent models on the dataset each time.\n",
    "2) The accuracy from simple Decision Trees and random Forest are good enough.\n",
    "\n",
    "Hence applying AdaBoost will not give us any significant advantage when considering time of execution and model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on AdaBoost Classifier -> 0.8142002924269907\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1, random_state=42), n_estimators=5, learning_rate = 2)\n",
    "clf.fit(X_train, y_train)\n",
    "print(f\"Accuracy on AdaBoost Classifier -> {clf.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model ran for a long time using just Decision Stumps and with small number of n_estimators. Still the accuracy is not high enough. This time will increase a lot when applied on larger base models and higher number of times. Thus we will not implement AdaBoost anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for completion, we will deploy some other models on the dataset and compare their accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianNB and MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on GaussianNB -> 0.46950817273254025\n",
      "Accuracy on MultinomialNB -> 0.20206020597339364\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "print(f\"Accuracy on GaussianNB -> {clf.score(X_test, y_test)}\")\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "print(f\"Accuracy on MultinomialNB -> {clf.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes Classifiers seem to perform much worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkernels = [\\'linear\\', \\'poly\\', \\'sigmoid\\', \\'precomputed\\', \\'rbf\\']\\n\\nfor k in kernels:\\n    clf = SVC(random_state = 42, kernel = k)\\n    clf.fit(X_train, y_train)\\n    print(f\"Accuracy on SVC (with kernel = {k}) -> {clf.score(X_test, y_test)}\")\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "kernels = ['linear', 'poly', 'sigmoid', 'precomputed', 'rbf']\n",
    "\n",
    "for k in kernels:\n",
    "    clf = SVC(random_state = 42, kernel = k)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f\"Accuracy on SVC (with kernel = {k}) -> {clf.score(X_test, y_test)}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVC models above have been commented out because none of the kernels seem to be able to fit the data. Even after running the model for \n",
    "around 12 hours on a Kaggle Notebook, it was unable to fit the data. This might happen because the data is too large for the Support Vector Classifiers to be able to fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying model on other datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we can imply that Decision Tree seems to give the best accuracy in comparately less time. We would deploy Decision Tree on the rest of the 12 datasets and check their accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {}\n",
    "df_dict[1] = pd.read_csv(\"C:\\\\Users\\\\Hp\\\\Downloads\\\\CTU-13\\\\9-Neris-20110817.binetflow.csv\")\n",
    "df_dict[2] = pd.read_csv(\"C:\\\\Users\\\\Hp\\\\Downloads\\\\CTU-13\\\\8-Murlo-20110816-3.binetflow.csv\")\n",
    "df_dict[3] = pd.read_csv(\"C:\\\\Users\\\\Hp\\\\Downloads\\\\CTU-13\\\\6-Menti-20110816.binetflow.csv\")\n",
    "df_dict[4] = pd.read_csv(\"C:\\\\Users\\\\Hp\\\\Downloads\\\\CTU-13\\\\7-Sogou-20110816-2.binetflow.csv\")\n",
    "df_dict[5] = pd.read_csv(\"C:\\\\Users\\\\Hp\\\\Downloads\\\\CTU-13\\\\4-Rbot-20110815.binetflow.csv\")\n",
    "df_dict[6] = pd.read_csv(\"C:\\\\Users\\\\Hp\\\\Downloads\\\\CTU-13\\\\5-Virut-20110815-2.binetflow.csv\")\n",
    "df_dict[7] = pd.read_csv(\"C:\\\\Users\\\\Hp\\\\Downloads\\\\CTU-13\\\\3-Rbot-20110812.binetflow.csv\")\n",
    "df_dict[8] = pd.read_csv(\"C:\\\\Users\\\\Hp\\\\Downloads\\\\CTU-13\\\\2-Neris-20110811.binetflow.csv\")\n",
    "df_dict[9] = pd.read_csv(\"C:\\\\Users\\\\Hp\\\\Downloads\\\\CTU-13\\\\13-Virut-20110815-3.binetflow.csv\")\n",
    "df_dict[10] = pd.read_csv(\"C:\\\\Users\\\\Hp\\\\Downloads\\\\CTU-13\\\\12-NsisAy-20110819.binetflow.csv\")\n",
    "df_dict[11] = pd.read_csv(\"C:\\\\Users\\\\Hp\\\\Downloads\\\\CTU-13\\\\10-Rbot-20110818.binetflow.csv\")\n",
    "df_dict[12] = pd.read_csv(\"C:\\\\Users\\\\Hp\\\\Downloads\\\\CTU-13\\\\11-Rbot-20110818-2.binetflow.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(c):\n",
    "    \n",
    "    df = df_dict[c]\n",
    "    \n",
    "    # Conversion to date-time\n",
    "    df[\"StartTime\"] = pd.to_datetime(df[\"StartTime\"])\n",
    "    \n",
    "    # Impute the missing value in the 'State' column with the mode (most frequent value) of the column\n",
    "    most_frequent_state = df['State'].mode()[0]\n",
    "    df['State'].fillna(most_frequent_state, inplace=True)\n",
    "\n",
    "    # Filling \"Unknown\" in place of nan values in Sport and Dport\n",
    "    df['Sport'].fillna('unknown', inplace=True)\n",
    "    df['Dport'].fillna('unknown', inplace=True)\n",
    "\n",
    "    # Replacing the nan values in sTos and dTos with the median of respective columns\n",
    "    df['sTos'].fillna(df[\"sTos\"].median(), inplace=True)\n",
    "    df['dTos'].fillna(df[\"dTos\"].median(), inplace=True)\n",
    "    \n",
    "    # Encoding Categorical Features using Label Encoding from scikit-learn\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # The Categorical variables we have to encode\n",
    "    categorical_cols = [\"Proto\", \"Dir\", \"State\", \"Sport\", \"Dport\"]\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "    # Encoding the Labels to integers\n",
    "    df[\"Label\"] = label_encoder.fit_transform(df[\"Label\"])\n",
    "\n",
    "    # Creating New Features\n",
    "    # Rate of packets per second\n",
    "    df['PacketsPerSec'] = df['TotPkts'] / df['Dur']\n",
    "    # Bytes per second\n",
    "    df['BytesPerSec'] = df['TotBytes'] / df['Dur']\n",
    "\n",
    "    # Replace any NaN or infinite values (with zero) generated during the feature engineering\n",
    "    df.replace([float('inf'), -float('inf')], float('nan'), inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    # Drop non-numeric columns and separate features (X) and target (y) variables\n",
    "    X = df.select_dtypes(include=['number']).drop(['Label'], axis=1, errors='ignore')\n",
    "    y = df['Label']\n",
    "    \n",
    "    df_dict[c] = (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing on the rest of 12 datasets\n",
    "for c in range(1,13):\n",
    "    preprocessing(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(c):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_dict[c][0], df_dict[c][1], test_size=0.3, random_state=42)\n",
    "    \n",
    "    clf = DecisionTreeClassifier(random_state=42, max_depth = 17)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f\"Accuracy on dataset {c} = {clf.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on dataset 1 = 0.8945873313181734\n",
      "Accuracy on dataset 2 = 0.9568900638519456\n",
      "Accuracy on dataset 3 = 0.9234595290918199\n",
      "Accuracy on dataset 4 = 0.9342566619915849\n",
      "Accuracy on dataset 5 = 0.9158398325419315\n",
      "Accuracy on dataset 6 = 0.9185365853658537\n",
      "Accuracy on dataset 7 = 0.9749177747963476\n",
      "Accuracy on dataset 8 = 0.9601299321395849\n",
      "Accuracy on dataset 9 = 0.9765039953596689\n",
      "Accuracy on dataset 10 = 0.9352839966407899\n",
      "Accuracy on dataset 11 = 0.8569189032366429\n",
      "Accuracy on dataset 12 = 0.9039656887120835\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree on those datasets\n",
    "for c in range(1,13):\n",
    "    model(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simple model like Decision Tree seems to fit all the datasets pretty nicely, with a few of them having lower accuracy. This states the fact that building machine learning models for classifying botnet traffic with significant accuracy is possible. Hence we can build more complex models and make them fit the data for longer duration of time, to get high accuracies when deployed in the real world.\n",
    "\n",
    "For making an overall good model, we can create a model for each of the datasets separately, fine-tune them and use a voting algorithm on all of them and then deploy this model on the real world. Now we can decide whether to use one model type each time or a collection of models. We could also combine these datasets, shuffle and divide them into a desired number of smaller datasets and then apply the above steps on them. The list of ideas goes on and on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
